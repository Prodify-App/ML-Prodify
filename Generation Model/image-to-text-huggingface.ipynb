{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!ls '/kaggle/input/shopee-product-images'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-29T05:18:39.434674Z","iopub.execute_input":"2023-05-29T05:18:39.434925Z","iopub.status.idle":"2023-05-29T05:18:40.388351Z","shell.execute_reply.started":"2023-05-29T05:18:39.434901Z","shell.execute_reply":"2023-05-29T05:18:40.387026Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"data_products_id_small.csv  data_products_id_tiny.csv  images\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q transformers==4.28.0 datasets gdown accelerate rouge_score","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:18:40.391136Z","iopub.execute_input":"2023-05-29T05:18:40.391817Z","iopub.status.idle":"2023-05-29T05:19:04.860564Z","shell.execute_reply.started":"2023-05-29T05:18:40.391780Z","shell.execute_reply":"2023-05-29T05:19:04.859427Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport urllib.request\nimport io\nimport os\nimport sys\nimport requests\nimport PIL\nimport datasets\n\n\nfrom PIL import Image\nfrom transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, TrainingArguments, Trainer\nfrom datasets import Dataset, load_dataset, load_from_disk, DatasetDict, load_metric\nfrom transformers import TFVisionEncoderDecoderModel, AutoImageProcessor, AutoTokenizer, VisionEncoderDecoderModel\n# from tensorflow.keras.optimizers import Adam\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:19:04.864387Z","iopub.execute_input":"2023-05-29T05:19:04.864703Z","iopub.status.idle":"2023-05-29T05:19:16.358437Z","shell.execute_reply.started":"2023-05-29T05:19:04.864674Z","shell.execute_reply":"2023-05-29T05:19:16.357473Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"img_root_folder = '/kaggle/input/shopee-product-images/images/download'\ntext_root_folder = '/kaggle/input/shopee-product-images/'","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:19:16.360844Z","iopub.execute_input":"2023-05-29T05:19:16.361205Z","iopub.status.idle":"2023-05-29T05:19:16.368829Z","shell.execute_reply.started":"2023-05-29T05:19:16.361173Z","shell.execute_reply":"2023-05-29T05:19:16.367629Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"products = pd.read_csv(f'{text_root_folder}/data_products_id_small.csv')\nprint(products['main_category'].value_counts().to_string())\nproducts = products.loc[products['main_category'] == 'Pakaian Pria']","metadata":{"execution":{"iopub.status.busy":"2023-05-29T05:19:16.370149Z","iopub.execute_input":"2023-05-29T05:19:16.370776Z","iopub.status.idle":"2023-05-29T05:19:17.246075Z","shell.execute_reply.started":"2023-05-29T05:19:16.370739Z","shell.execute_reply":"2023-05-29T05:19:17.245009Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Olahraga & Outdoor           13050\nElektronik                   11510\nPerawatan & Kecantikan       10479\nPakaian Wanita                9333\nPerlengkapan Rumah            8932\nAksesoris Fashion             8912\nPakaian Pria                  7888\nIbu & Bayi                    7474\nKomputer & Aksesoris          7365\nKesehatan                     6969\nOtomotif                      6843\nHobi & Koleksi                6592\nBuku & Alat Tulis             6512\nHandphone & Aksesoris         5983\nFashion Bayi & Anak           5940\nTas Wanita                    5926\nSepatu Wanita                 5911\nFashion Muslim                5500\nMakanan & Minuman             5498\nSepatu Pria                   4500\nTas Pria                      4189\nJam Tangan                    2491\nSouvenir & Party Supplies     2477\nFotografi                     1931\n","output_type":"stream"}]},{"cell_type":"code","source":"def generate_img_path(product_id, image, main_category, sub_category):\n    return f\"{img_root_folder}/{main_category}/{sub_category}/{image}_tn-{product_id}.jpeg\"\n\nproducts['image_path'] = products.apply(lambda x: generate_img_path(x.product_id, x.image, x.main_category, x.sub_category), axis=1)\nproducts = products.drop(['product_id', 'image', 'shop_name', 'shopid', 'main_category', 'sub_category'], axis=1)\n\nfor index, product in tqdm(products.iterrows(), desc='Check Images', total=products.shape[0]):\n  if not os.path.exists(product['image_path']):\n    print(\"Not Found\")","metadata":{"execution":{"iopub.status.busy":"2023-05-22T07:26:22.460140Z","iopub.execute_input":"2023-05-22T07:26:22.460525Z","iopub.status.idle":"2023-05-22T07:27:05.727437Z","shell.execute_reply.started":"2023-05-22T07:26:22.460490Z","shell.execute_reply":"2023-05-22T07:27:05.726466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_val_df, test_df = train_test_split(products, test_size=0.2, random_state=42)\ntrain_df, val_df = train_test_split(train_val_df, test_size=0.1, random_state=42)\n\ntrain_df.reset_index(drop=True, inplace=True)\nval_df.reset_index(drop=True, inplace=True)\ntest_df.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T07:27:05.729164Z","iopub.execute_input":"2023-05-22T07:27:05.729549Z","iopub.status.idle":"2023-05-22T07:27:06.017637Z","shell.execute_reply.started":"2023-05-22T07:27:05.729515Z","shell.execute_reply":"2023-05-22T07:27:06.016710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom PIL import Image\n\nclass CaptioningDataset(Dataset):\n    def __init__(self, df, tokenizer, img_processor, max_target_length=100):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.img_processor = img_processor\n        self.max_target_length = max_target_length\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_path = self.df['image_path'][idx]\n        title = self.df['name'][idx].lower()\n\n        image = Image.open(img_path).convert(\"RGB\")\n        pixel_values = self.img_processor(image, return_tensors=\"pt\").pixel_values\n\n        encoded_title = self.tokenizer(title, padding=\"max_length\", max_length=self.max_target_length, truncation=True)\n\n        labels = [label if label != self.tokenizer.pad_token_id else -100 for label in encoded_title.input_ids]\n\n        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(labels)}\n        return encoding","metadata":{"execution":{"iopub.status.busy":"2023-05-22T07:27:06.018810Z","iopub.execute_input":"2023-05-22T07:27:06.019141Z","iopub.status.idle":"2023-05-22T07:27:06.027849Z","shell.execute_reply.started":"2023-05-22T07:27:06.019111Z","shell.execute_reply":"2023-05-22T07:27:06.026721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n#     outputs = [self.bos_token_id] + token_ids_0 + [self.eos_token_id]\n#     return outputs\n\n# GPT2Tokenizer.build_inputs_with_special_tokens = build_inputs_with_special_tokens","metadata":{"execution":{"iopub.status.busy":"2023-05-22T07:27:06.029609Z","iopub.execute_input":"2023-05-22T07:27:06.030171Z","iopub.status.idle":"2023-05-22T07:27:06.045062Z","shell.execute_reply.started":"2023-05-22T07:27:06.030138Z","shell.execute_reply":"2023-05-22T07:27:06.044144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder_pretrained = 'google/vit-base-patch16-224'\ndecoder_pretrained = 'indolem/indobert-base-uncased'\n\nimage_processor = AutoImageProcessor.from_pretrained(encoder_pretrained)\ntokenizer = AutoTokenizer.from_pretrained(decoder_pretrained)\n\n#gpt2\n# tokenizer.pad_token = tokenizer.unk_token\n\n#bert","metadata":{"execution":{"iopub.status.busy":"2023-05-22T07:27:06.048891Z","iopub.execute_input":"2023-05-22T07:27:06.049170Z","iopub.status.idle":"2023-05-22T07:27:08.278922Z","shell.execute_reply.started":"2023-05-22T07:27:06.049125Z","shell.execute_reply":"2023-05-22T07:27:08.277983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = CaptioningDataset(df=train_df, tokenizer=tokenizer, img_processor=image_processor)\neval_dataset = CaptioningDataset(df=val_df, tokenizer=tokenizer, img_processor=image_processor)\ntest_dataset = CaptioningDataset(df=test_df, tokenizer=tokenizer, img_processor=image_processor)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T07:27:08.280514Z","iopub.execute_input":"2023-05-22T07:27:08.280888Z","iopub.status.idle":"2023-05-22T07:27:08.286655Z","shell.execute_reply.started":"2023-05-22T07:27:08.280844Z","shell.execute_reply":"2023-05-22T07:27:08.285443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of training examples:\", len(train_dataset))\nprint(\"Number of validation examples:\", len(eval_dataset))\n\nencoding = train_dataset[0]\nfor k,v in encoding.items():\n  print(k, v.shape)\n\nlabels = encoding['labels']\nprint(labels)\n\nlabels[labels == -100] = tokenizer.pad_token_id\nlabel_str = tokenizer.decode(labels, skip_special_tokens=True)\nprint('Decoded Label:', label_str)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T07:27:08.288287Z","iopub.execute_input":"2023-05-22T07:27:08.288639Z","iopub.status.idle":"2023-05-22T07:27:08.389000Z","shell.execute_reply.started":"2023-05-22T07:27:08.288608Z","shell.execute_reply":"2023-05-22T07:27:08.388015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = Image.open(train_df['image_path'][0]).convert(\"RGB\")\nprint('Label: '+train_df['name'][0])\nimage","metadata":{"execution":{"iopub.status.busy":"2023-05-22T07:27:08.390238Z","iopub.execute_input":"2023-05-22T07:27:08.390559Z","iopub.status.idle":"2023-05-22T07:27:08.441164Z","shell.execute_reply.started":"2023-05-22T07:27:08.390527Z","shell.execute_reply":"2023-05-22T07:27:08.440373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rouge = load_metric(\"rouge\")\n\ndef compute_metrics(pred):\n    labels_ids = pred.label_ids\n    pred_ids = pred.predictions\n\n    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n\n    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n\n    return {\n        \"rouge2_precision\": round(rouge_output.precision, 4),\n        \"rouge2_recall\": round(rouge_output.recall, 4),\n        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n    }","metadata":{"execution":{"iopub.status.busy":"2023-05-22T07:27:08.442052Z","iopub.execute_input":"2023-05-22T07:27:08.442381Z","iopub.status.idle":"2023-05-22T07:27:09.554988Z","shell.execute_reply.started":"2023-05-22T07:27:08.442353Z","shell.execute_reply":"2023-05-22T07:27:09.554019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(encoder_pretrained, decoder_pretrained)\n\n#gpt2\n# model.config.decoder_start_token_id = tokenizer.bos_token_id\n# model.config.pad_token_id = tokenizer.pad_token_id\n# model.config.vocab_size = model.config.decoder.vocab_size\n# model.config.eos_token_id = tokenizer.eos_token_id\n\n#bert\nmodel.config.decoder_start_token_id = tokenizer.cls_token_id\nmodel.config.pad_token_id = tokenizer.pad_token_id\nmodel.config.vocab_size = model.config.decoder.vocab_size\n\nmodel.config.max_length = 100\nmodel.config.early_stopping = True\nmodel.config.no_repeat_ngram_size = 3\nmodel.config.length_penalty = 2.0\nmodel.config.num_beams = 4","metadata":{"execution":{"iopub.status.busy":"2023-05-22T07:27:09.556351Z","iopub.execute_input":"2023-05-22T07:27:09.556711Z","iopub.status.idle":"2023-05-22T07:27:16.937412Z","shell.execute_reply.started":"2023-05-22T07:27:09.556677Z","shell.execute_reply":"2023-05-22T07:27:16.936514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import default_data_collator, EarlyStoppingCallback\nfrom transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n\nearly_stop = EarlyStoppingCallback(early_stopping_patience=3)\n\ntraining_args = Seq2SeqTrainingArguments(\n    num_train_epochs=100,\n    predict_with_generate=True,\n    evaluation_strategy=\"epoch\",\n    logging_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    per_device_train_batch_size=24,\n    per_device_eval_batch_size=24,\n    fp16=True, \n    output_dir=\".\",\n    overwrite_output_dir=True,\n    save_total_limit=1,\n    report_to=\"none\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"rouge2_fmeasure\"\n)\n\n# instantiate trainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    tokenizer=image_processor,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    data_collator=default_data_collator,\n    callbacks=[early_stop]\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-05-22T07:27:16.938717Z","iopub.execute_input":"2023-05-22T07:27:16.939056Z","iopub.status.idle":"2023-05-22T08:49:50.961597Z","shell.execute_reply.started":"2023-05-22T07:27:16.939023Z","shell.execute_reply":"2023-05-22T08:49:50.960727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained('perawatan-kecantikan')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.predict(test_dataset=test_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T08:49:50.963073Z","iopub.execute_input":"2023-05-22T08:49:50.963446Z","iopub.status.idle":"2023-05-22T09:00:27.286435Z","shell.execute_reply.started":"2023-05-22T08:49:50.963413Z","shell.execute_reply":"2023-05-22T09:00:27.285464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\np_id = random.randrange(0, len(test_df))\nimage = Image.open(test_df['image_path'][p_id]).convert(\"RGB\")\ntitle = test_df['name'][p_id]\n\npixel_values = image_processor(image, return_tensors=\"pt\").pixel_values.to(torch.device(\"cuda\"))\nlabels = tokenizer(title, return_tensors=\"pt\").input_ids.to(torch.device(\"cuda\"))\n\nprint(title)\nimage","metadata":{"execution":{"iopub.status.busy":"2023-05-22T09:11:50.439671Z","iopub.execute_input":"2023-05-22T09:11:50.440054Z","iopub.status.idle":"2023-05-22T09:11:50.484698Z","shell.execute_reply.started":"2023-05-22T09:11:50.440024Z","shell.execute_reply":"2023-05-22T09:11:50.483642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generated_ids = model.generate(pixel_values, num_return_sequences=3)\ngenerated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n# print(generated_ids)\n# print(generated_text)\n\nfor t in generated_text:\n    print(t)\n    print()    ","metadata":{"execution":{"iopub.status.busy":"2023-05-22T09:11:52.563209Z","iopub.execute_input":"2023-05-22T09:11:52.564071Z","iopub.status.idle":"2023-05-22T09:11:54.202619Z","shell.execute_reply.started":"2023-05-22T09:11:52.564035Z","shell.execute_reply":"2023-05-22T09:11:54.201645Z"},"trusted":true},"execution_count":null,"outputs":[]}]}